#! /usr/bin/env python
"""
Filename: evaluate.py
Author: Emily Daniels
Date: May 2016
Purpose: A Naive Bayes classifier determines if the poems generated by a
recurrent neural network trained on a collection of one author's novels would
also reflect the writing style of a second author and retains the poems at
that intersection.
"""
from __future__ import print_function
from nltk.classify import PositiveNaiveBayesClassifier
import csv
import os
import nltk
import itertools
from generate import Generate
from datetime import datetime


def split_text(filename):
    with open(filename, 'rU') as f:
        reader = csv.reader(f, skipinitialspace=True)
        reader.next()
        # extra decoding to account for non UTF-8 characters
        sentences = itertools.chain(*[nltk.sent_tokenize(
            x[0].decode('latin-1').encode('utf-8').decode('utf-8').lower()) for
                                      x in reader])
    return sentences


def features(sentence):
    words = sentence.lower().split()
    return dict(('contains(%s)' % w, True) for w in words)


def write_poems(train_file, compare_file, poems):
    filename = 'Poems_of_' + os.path.basename(
        train_file) + '_ala_' + os.path.basename(compare_file) + '_' + str(
        datetime.now().strftime("%Y-%m-%d %H-%M-%S")) + '.txt'
    with open(filename, "wb") as f:
        for poem in poems:
            f.write("%s\n" % poem)


if __name__ == "__main__":
    # define the parameters to be used to train the model-
    # here some standard values are used
    # these can be changed when first training a model, but if using a
    # pre-trained model they must match what was used
    vocabulary_size = 8000
    hidden_dim = 80
    learning_rate = 0.005
    nepoch = 100

    # this parameter is set to false so that the most recent model file will be
    # loaded and used- if the model has not been trained, set it to true to
    # start the training
    enable_training = True

    # create a csv file of the first author's novels stripped of anything
    # not part of the text
    train_file = 'data/austen.csv'

    # create a csv file of the second author's novels stripped of anything
    # not part of the text
    compare_file = 'data/h.g.wells.csv'

    # either the most recently trained file or use none to start a new training
    model_file = 'data/rnn-austen-80-8000-2016-04-19-14-09-39.npz'

    # the number of sentences the model should generate and use to select haiku
    # worthy lines
    num_sentences = 1000

    # generate haiku poems from the first author's novels
    print("Generating poems...")
    generate = Generate(vocabulary_size, hidden_dim, learning_rate, nepoch,
                        enable_training, model_file, train_file, num_sentences)
    poems = generate.poems

    # train the classifier to distinguish between the different writing styles
    print("Training classifier...")
    first_author_sentences = split_text(train_file)
    second_author_sentences = split_text(compare_file)
    positive_featuresets = list(map(features, second_author_sentences))
    unlabeled_featuresets = list(map(features, first_author_sentences))
    classifier = PositiveNaiveBayesClassifier.train(positive_featuresets,
                                                    unlabeled_featuresets)

    filtered_poem_list = []
    for poem in poems:
        if classifier.classify(features(poem)):
            filtered_poem_list.append(poem)

    # write the filtered list of poems to a text file
    print("Writing poems to file...")
    write_poems(train_file, compare_file, filtered_poem_list)
